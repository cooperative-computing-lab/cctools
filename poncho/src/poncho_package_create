#!/usr/bin/env python3

# Copyright (C) 2020- The University of Notre Dame
# This software is distributed under the GNU General Public License.
# See the file COPYING for details.

import os
import sys
import tempfile
import argparse
import subprocess
import json
import conda_pack

devnull = open(os.devnull, 'w')

def pack_env(spec, out):
    with tempfile.TemporaryDirectory() as env_dir:
        print('Creating temporary environment in {}'.format(env_dir))
	
	# creates conda spec file from original spec file
        print('creating conda environment...')
        check_spec(spec, env_dir)
	
        subprocess.check_call(['conda', 'env', 'create', '--prefix', env_dir,
            '--file', env_dir + '/conda_spec.yml'])

	# fetch data
        print('Fethcing data...')
        git_data(spec, env_dir)
        http_data(spec, env_dir)
	
        # Bug breaks bundling common packages (e.g. python).
        # ignore_missing_files may be safe to remove in the future.
        # https://github.com/conda/conda-pack/issues/145
        print('packing environment...')
        conda_pack.pack(prefix=env_dir, output=out, force=True, ignore_missing_files=True)
        print('To activate environment run poncho_package_run -e {} <command>'.format(out))

def git_data(spec, out_dir):

    f = open(spec, 'r')
    data = json.load(f)
    
    if 'git' in data:
        for git_dir in data['git']:

            git_repo = None
            ref = None

            if 'remote' in data['git'][git_dir]:
                git_repo = data['git'][git_dir]['remote']
            if 'ref' in data['git'][git_dir]:
                ref = data['git'][git_dir]['ref']

            if git_repo:
                # clone repo
                path = '{}/{}'.format(out_dir, git_dir)

                subprocess.check_call(['git', 'clone', git_repo, path])
            
                if not os.path.exists(out_dir + '/poncho'):
                    os.mkdir(out_dir + '/poncho')

                # add to script
                gd = 'export {}=$1/{}\n'.format(git_dir, git_dir) 
                with open(out_dir + '/poncho/set_env', 'a') as f:
                    f.write(gd)
            	
def http_data(spec, out_dir):

    f = open(spec, 'r')
    data = json.load(f)

    if 'http' in data:
        for filename in data['http']:

            file_type = None
            compression = None
            url = None

            if 'type' in data['http'][filename]:
                file_type = data['http'][filename]['type']
            if 'compression' in data['http'][filename]:
                compression = data['http'][filename]['compression']
            if 'url' in data['http'][filename]:
                url = data['http'][filename]['url']

            if url:
                # curl datai
                path = '{}/{}'.format(out_dir, filename)
              
                if file_type == 'tar' and compression == 'gzip':
                    tgz = path + '.tar.gz'
                    subprocess.check_call(['curl', url, '--output', tgz])
                    os.mkdir(path)
                    subprocess.check_call(['tar', '-xzf', tgz, '-C', path])

                elif file_type == 'tar':
                    tar = path + '.tar'
                    subprocess.check_call(['curl', url, '--output', tar])
                    os.mkdir(path)
                    subprocess.check_call(['tar', '-xf', tar, '-C', path])

                elif compression == 'gzip':
                    gz = path + '.gz'
                    subprocess.check_call(['curl', url, '--output', gz])
                    subprocess.check_call(['gzip', '-d', gz])

                else:
                    subprocess.check_call(['curl', url, '--output', path])
                
                if not os.path.exists(out_dir + '/poncho'):
                    os.mkdir(out_dir + '/poncho')

                gd = 'export {}=$1/{}\n'.format(filename, filename) 
                with open(out_dir + '/poncho/set_env', 'a') as f:
                    f.write(gd)

def check_spec(spec, out_dir):

    f = open(spec, 'r')
    data = json.load(f)
    conda_spec = {}
    conda_spec['channels'] = []
    conda_spec['dependencies'] = []
    conda_spec['name'] = 'base'
 
    if 'conda' in data:
        for  channel in data['conda']['channels']:
            if channel not in conda_spec['channels']:
                conda_spec['channels'].append(channel)
        for  dep in data['conda']['packages']:
            if dep not in conda_spec['dependencies']:
                conda_spec['dependencies'].append(dep)


    if 'pip' in data:
        pip_pkgs = []
        for x in data['pip']:
            pip_pkgs.append(x)

        conda_spec['dependencies'].append({'pip':pip_pkgs})

    with open(out_dir + '/conda_spec.yml',  'w') as jf:
        json.dump(conda_spec, jf, indent=4)			
	
if __name__ == '__main__':
    parser = argparse.ArgumentParser(
        description='Create a packed environment from a spec.')
    parser.add_argument('spec',
        help='Read in a spec file, or - for stdin.')
    parser.add_argument('out',
        help='Write output from conda-pack to the given file.')
    args = parser.parse_args()	
    pack_env(args.spec, args.out)
