# Poncho Packaging Utilities

The Poncho packaging utilities allow users to easily analyze their Python scripts and create Conda environments that are specifically built to contain the necessary dependencies required for their application to run. In distributed computing systems such as Work Queue, it is often difficult to maintain homogenous work environments for their Python applications, as the scripts utilize a large number of outside resources at runtime, such as Python interpreters and imported libraries. The Python packaging collection provides three easy-to-use tools that solve this problem, helping users to analyze their Python programs and build the appropriate Conda environments that ensure consistent runtimes within the Work Queue system. 

The `poncho_package_analyze` tool analyzes a Python script to determine all its top-level module dependencies and the interpreter version it uses. It then generates a concise, human-readable JSON output file containing the necessary information required to build a self-contained Conda virtual environment for the Python script.

The `poncho_package_create` takes a enviornment specification JSON file  and creates this Conda environment, preinstalled with all the necessary libraries and the correct Python interpreter version. It then generates a packaged tarball of the environment that can be easily relocated to a different machine within the system to run the Python task.

The `poncho_package_run` tool acts as a wrapper script for the Python task, unpacking and activating the Conda environment and running the task within the environment.



# poncho_package_analyze(1)

## NAME

`poncho_package_analyze` - command-line utility for analyzing Python script for library and interpreter dependencies

## SYNOPSIS

`poncho_package_analyze [options] <python-script ...> <json-output-file>`

## DESCRIPTION

`poncho_package_analyze` is a simple command line utility for analyzing Python scripts for the necessary external dependencies. It generates an output file that can be used with `python_package_create` to build a self-contained Conda environment for the Python application.

The `python-script ...` argument is the path(s) to the Python script(s) to be analyzed. The `json-output-file` argument is the path to the output JSON file that will be generated by the command. Specifying `-` for either will use `stdin`/`stdout` instead of a file.

## OPTIONS

-h, --help                   Show this help message
--toplevel                   Only include imports at the top level of the script.
--function FUNCTION          Only include imports in the given function.
--pkg-mapping IMPORT=NAME    Specify that the module imported as IMPORT in the
                             code is provided by the pip/conda package NAME.
--extra-pkg                  Also include the pip/conda package PKG, even if
                             it does not appear in the sources. May be useful
                             for scripts that execute other (possibly
                             non-Python) components that must also be included.

## EXIT STATUS

On success, returns zero. On failure, returns non-zero.

## EXAMPLE

An example Python script `example.py` contains the following code:

```
import os
import sys
import pickle

import antigravity
import matplotlib


if __name__ == "__main__":
    print("example")
```

To analyze the `example.py` script for its dependencies and generate the output JSON dependencies file `dependencies.json`, run the following command:

`$ poncho_package_analyze example.py dependencies.json`

Once the command completes, the `dependencies.json` file within the current working directory will contain a Conda environment specification
(suitable to use with `conda env create`).

Note that system-level modules are considered part of the Python package installed into the Conda environment.
Additionally, imports not managed by Pip or Conda are not allowed.
This includes other modules within the CWD or in user-written packages.


# poncho_package_create(1)

## NAME

`poncho_package_create` - command-line utility for creating a Conda virtual environment given a Python dependencies file

## SYNOPSIS

`poncho_package_create [options] <dependency-file> <output-path>`

## DESCRIPTION

`poncho_package_create` is a simple command-line utility that creates a local Conda environment from an input JSON dependency file.
The command creates an environment tarball at `output-path` that can be sent to and run on different machines with the same architecture.

The `dependency-file` argument is the path (relative or absolute) to the a JSON specification file. The `output-path` argument specifies the path for the environment tarball that is created
(should usually end in `.tar.gz`).

## OPTIONS

-h        Show this help message

## EXIT STATUS

On success, returns zero. On failure, returns non-zero.

## EXAMPLE

`$ poncho_package_create dependencies.json example_venv.tar.gz`

This will create an `example_venv.tar.gz` environment tarball within the current working directory, which can then be exported to different machines for execution.



# poncho_package_run(1)

## NAME

`poncho_package_run` - wrapper script that executes Python script within an isolated Conda environment

## SYNOPSIS

`poncho_package_run [options] --environment <file> command and args ...`

## DESCRIPTION

The `poncho_package_run` tool acts as a wrapper script for a Python task, running the task within the specified Conda environment. `poncho_package_run` can be utilized on different machines within the Work Queue system to unpack and activate a Conda environment, and run a task within the isolated environment.

The `--environment <file>` argument is the name of the Conda environment as a tarball file in which to run the Python task.
`command and args` (the `COMMAND`) are interpreted as `ARGV` for a command to be run inside the Conda environment.

By default, the conda environment is unpacked into a temporary directory which is removed at the end of execution. If the `--unpack-to <dir>` is given, then the environment is unpacked to `<dir>`, and it is not removed at the end of execution. Further (even simultaneous) executions of `python_package_run` will not unpack the environment if `<dir>` is already populated. Instances of `python_package_run` coordinate via a writing lock. By default, the wait for a writing lock is 300 seconds, but this can be modified with the `--wait-for-lock <secs>` option.

If the argument to `--unpack-to` does not exist, then it is created as an empty directory. If it is an existing directory, but it is not empty, then unpacking is not performed, regardless on whether this directory contains a valid conda environment.


## OPTIONS 

-e, --environment <file>   Conda environment as a tar file. (Required.)
-d, --unpack-to <dir>      Directory to unpack the environment. If not given,
                           a temporary directory is used.
-w, --wait-for-lock <secs> Number of seconds to wait to get a writing lock
                           on <dir>. Default is 300.
-h, --help                 Show the help screen.
command and args           Command to execute inside the given environment.

## EXIT STATUS

On success, returns 0. On failure, returns non-zero.

## EXAMPLE

`poncho_package_run --environment example_venv.tar.gz python3 example.py`

This will run the command `python3 example.py` within the Conda environment in `example_venv.tar.gz`. Note that this command can be performed either locally, on the same machine that analyzed the script and created the environment, or remotely, on a different machine that contains the Conda environment tarball and the `example.py` script.

`poncho_package_run --unpack-to my_persistent_env --environment example_venv.tar.gz python3 example.py`

The previous command will run faster the second time it is executed, as the
environment is only unpacked once to `my_persistent_env`.


# HOW TO TEST OVERALL FUNCTIONALITY

Desired Python script to run: `hi.py`

1. `./poncho_package_analyze hi.py output.json`
- Generates the appropriate JSON file in the current working directory
2. `./poncho_package_create output.json venv.tar.gz`
- Will create a packed tarball of the environment named `venv.tar.gz` in the current working directory
3. `./poncho_package_run --environment venv.tar.gz python3 hi.py`
- Runs the `python3 hi.py` task command within the `venv.tar.gz` Conda environment

Poncho Environment Specification Format
=======================================

Environment Specifications are declarative JSON-encoded documents
defining software and/or data requirements for executing a particular
task. This format currently supports packages via Conda and Pip,
and data via Git and HTTP fetch of an archive file.
Poncho Environment Specifications primarily set up the global interpreter
state, including the module search path, `$PATH`, and certain environment
variables. The steps to prepare an environment
may be expensive (e.g. building a Conda prefix), so systems should
perform caching and intelligent management where possible.
In general, after preparing an environment once on a node
it should be possible to run additional tasks in the same environment
almost instantly (as long as the cache can hold everything).

This format is similar to the `environment.yml` file used by Conda,
but includes additional features for fetching arbitrary data,
handling certificates, and similar setup activities that are
commonly encountered when dealing with scientific applications.
It is also designed to work from a different perspective:
whereas Conda provides command-line utilities for interactively
manipulating a shell environment tied to the user's `.bashrc`,
Environment Specifications are designed as plumbing components
for executing individual pieces of Python code, and can set up
state *within* a Python interpreter.
This format is meant to be a self-contained and portable artifact,
so it should not depend on the user's configuration, absolue paths,
or system-specific details where possible.

Conda Packages
--------------

```
{
	"conda": {
		"channels":[
                        "defaults",
			"conda-forge" 
		],
		"packages":[
			"python=3.7",
			"numpy=1.20.0=py38h18fd61f_0",
			"ndcctools"
		]
	}
}
```

The `"conda"` key, if present, gives a list of strings.
Each string must be a valid Conda package specification.
Conda package specifications SHOULD use the full three-item
specifications,

```
channel::package=version=build
```

if coming from an existing user install. This is because the
particular build in use may affect performance and functionality
(e.g. whether GPU support is available).
Conda supports a fairly rich syntax, documented
[here](https://docs.conda.io/projects/conda/en/latest/user-guide/concepts/pkg-specs.html#package-match-specifications).
Implementers should use the `conda.models.match_spec.MatchSpec`
class for parsing and validation.
This class is part of the Conda package
(The library, not the command line tool.
It may be necessary to run `conda install conda`.)
Classes for version comparison are also available,
as Conda uses its own flavor of version numbering.

Note that Environment Specifications do not include any way to
specify the Conda channels a user has configured.
This is intentional,
since Environment Specification should not depend on
the user's `.condarc`. Each package specification MUST
specify a channel using the `channel::package` syntax.
The channel will likely be `conda-forge` for most packages.
If generating an Environment Specification from a user's existing
Conda prefix, be sure to capture the channel used.
When building a Conda prefix from an Environment Specification,
it should not be necessary to perform any channel configuration.

Pip Packages
------------

```
{
	"pip": {
		"parsl",
		"ipython==7.20.0"
	}
}
```

The `"pip"` key, if present, gives a list of Pip package specifications.
Pip specifications SHOULD include the exact version if coming from an
existing user install. Package specifications are given as strings,
which must conform to
[PEP 508](https://www.python.org/dev/peps/pep-0508/)
usually seen in Pip's `requirements.txt` file.
Note that not all allowed input in `requirements.txt` is allowed here,
e.g. `-e .` is not a valid package specification.
The Setuptools package includes a class for parsing requirements
[here](https://setuptools.readthedocs.io/en/latest/pkg_resources.html#requirement-objects)
along with version comparison and feature detection.
Implementors should use the `Requirement` class to validate
package specifications.

It is also sometimes necessary to work with locally available packages
(often installed via `pip install -e .`).
Due to the added difficulties in managing such dependencies,
such packages are outside the scope of this document.
It may be necessary to use another tool to
detect and prepare local Pip package installations.

Git Checkout
------------

```
{
	"git": {
		"DATA_DIR": {
			"remote": "http://.../repo.git",
			"tag": "abcd1234...."
		}
	}
}
```

Some tasks might depend on data from a particular Git repository.
When running many short-lived tasks, it is undesirable to fetch
a large amount of data each time. Here, a runtime system may download
a particular Git repository once and serve many tasks that depend on it.
Specifications SHOULD refer to specific commits, since branches are
subject to change over time.
In this example, the given repo would be cloned into a common temporary
directory, the path to which is stored in a enviornment variable,
e.g. calling `DATA_DIR = Path(/tmp/whatever)` in the task runner before
invoking the user's function.
Subsequent tasks that request the same repo can simply have
this variable set by the runner. The management layer may clear the repo
from its cache at any time, though it should make an effort to keep
frequently used repositories available for fast access.

HTTP Fetch
----------

```
{
	"http": {
		"REFERENCE_DB": {
			"type": "file",
			"url": "https://.../example.dat"
		},
		"TRAINING_DATASET": {
			"type": "tar",
			"compression": "gzip",
			"url": "http://.../dataset.tar.gz"
		}
	}
}
```

HTTP fetch provides similar functionality to Git checkout, but
using a different transport. The URL is required and may be
HTTP or HTTPS. If a compression type is specified, the file
will be decompressed as part of the download process. If the
type is given as `"file"`, there is no further processing required
and the path of the downloaded file will be set as a environment
variable.

If type is `"tar"`, the (possibly decompressed)
file will be passed through `tar` and extracted into a temporary
directory (`tar -C`). The path to this directory will be stored
in the corresponding enviornment variable. If "compression" is
specified, the file will be decompressed.

----------------

Chached Imports

Management of keys/certificates
- Not sure about the most ergonomic way to do this
- Unless it's just pubkeys, not safe to include directly in the spec

Function Closures
- It would be possible (albeit inefficient given binary encoding in JSON)
  to include a pickled function + inputs in the same document, giving a
  portable Python function closure
- Also need specifications for resources
- Not sure if it's better to add those to the same document, or make
  Environment Specifications a field in another thing
