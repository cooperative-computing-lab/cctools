<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd"> 
<html>

<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.code_area {
font-family: monospace;
width: 98%;
margin: 1%;
border: solid 1px black;
}
.code_header {
text-decoration:underline;
background: #F4F4AE;
margin: 0%;
padding: 0.3%;
}
.code_snip {
background: #FFFFCC;
margin: 0%;
padding: 0.3%;
}
</style>

<title>Work Queue User's Manual</title>
</head>

<body>

<h1>Work Queue User's Manual</h1>
<b>Last Updated June 2013</b>
<p>
Work Queue is Copyright (C) 2009 The University of Notre Dame.
This software is distributed under the GNU General Public License.
See the file COPYING for details.
<p> 
<h2>Overview</h2>

<p>
Work Queue is a framework for building master/worker applications.
In Work Queue, a Master process is a custom, application-specific program
that uses the Work Queue API to define and submit a large number
of small tasks.  The tasks are executed by many Worker processes,
which can run on any available machine.  A single Master may direct
hundreds to thousands of Workers, allowing users to easily construct
highly scalable programs.
<p>
Work Queue is a stable framework that has been used to create
highly scalable scientific applications in biometrics, bioinformatics,
economics, and other fields.  It can also be used as an execution engine
for the <a href="http://www.cse.nd.edu/~ccl/software/makeflow">Makeflow</a> workflow engine.
<p>

<h2>Installing Work Queue</h2>
<p>
Work Queue is part of the <a href="http://www.cse.nd.edu/~ccl/software">Cooperating Computing Tools</a>.  
The CCTools package can be downloaded from <a href="http://www.cse.nd.edu/~ccl/software/download">this web page</a>.
Follow the <a href=install.html>installation instructions</a> to setup CCTools
required for running Work Queue.  The documentation for the full set of features
of the Work Queue API can be viewed from either within the CCTools package or 
<a href="http://www.cse.nd.edu/~ccl/software/manuals/api/html/work__queue_8h.html">here</a>
and <a href="http://www.cse.nd.edu/~ccl/software/manuals/api/html/namespaceWorkQueuePython.html">here</a>.

<h2>Building Work Queue Application</h2>

Let's begin by running a simple but complete example of a Work Queue
application. After trying it out, we will then show how to write a Work Queue
application from scratch.
<p>
We assume that you have downloaded and installed the cctools package in the
directory CCTOOLS. Next, download the example file for the language of your
choice: 
<ul>
<li>C: <a href=work_queue_example.c>work_queue_example.c</a></li>
<li>Python: <a href=work_queue_example.py>work_queue_example.py</a></li>
<li>Perl: <a href=work_queue_example.pl>work_queue_example.pl</a></li>
</ul>

If you are using the C example, compile it like this:
<div class ="code_area"><pre class="code_snip">
gcc work_queue_example.c -o work_queue_example -I${CCTOOLS}/include/cctools -L${CCTOOLS}/lib -ldttools -lm
</pre></div>
If you are using the Python example, set PYTHONPATH to include the Python modules in cctools:
<div class ="code_area"><pre class="code_snip">
export PYTHONPATH=${PYTHONPATH}:${CCTOOLS}/lib/python2.6/site-packages
</pre></div>
If you are using the Perl example, set PERL5LIB to include the Perl modules in cctools:
<div class ="code_area"><pre class="code_snip">
export PERL5LIB=${PERL5LIB}:${CCTOOLS}/lib/perl5/site_perl
</pre></div>

<h2>Running Work Queue Application</h2>
The example application simply compresses a bunch of files in parallel. The
files to be compressed must be listed on the command line. Each will be
transmitted to a remote worker, compressed, and then sent back to the Work Queue
master.

To compress files <tt>a</tt>, <tt>b</tt>, and <tt>c</tt> with this example
application, run it as:
<div class ="code_area"><pre class="code_snip">
./work_queue_example a b c
</pre></div>

You will see this right away:
<div class ="code_area"><pre class="code_snip">
listening on port 9123...
submitted task: /usr/bin/gzip < a > a.gz
submitted task: /usr/bin/gzip < b > b.gz
submitted task: /usr/bin/gzip < c > c.gz
waiting for tasks to complete...
</pre></div>

The Work Queue master is now waiting for workers to connect and begin requesting
work. (Without any workers, it will wait forever.) You can start one worker on
the same machine by opening a new shell and running:

<div class ="code_area"><pre class="code_snip">
work_queue_worker MACHINENAME 9123
</pre></div>

(Obviously, substitute the name of your machine for MACHINENAME.)  If you have
access to other machines, you can <tt>ssh</tt> there and run workers as well.
In general, the more you start, the faster the work gets done.
If a worker should fail, the work queue infrastructure will retry the work
elsewhere, so it is safe to submit many workers to an unreliable
system.
<p>
If you have access to a Condor pool, you can use this shortcut to submit
ten workers at once via Condor:
<div class ="code_area"><pre class="code_snip">
% condor_submit_workers MACHINENAME 9123 10 
Submitting job(s).......... 
Logging submit event(s).......... 
10 job(s) submitted to cluster 298.
</pre></div>

Or, if you have access to an SGE cluster, do this:
<div class ="code_area"><pre class="code_snip">
% sge_submit_workers MACHINENAME 9123 10 
Your job 153083 ("worker.sh") has been submitted 
Your job 153084 ("worker.sh") has been submitted 
Your job 153085 ("worker.sh") has been submitted 
...
</pre></div>

<p>
When the master completes, if the workers were not shut down in the
master, your workers will still be available, so you can either run
another master with the same workers, or you can remove the workers
with <tt>kill</tt>, <tt>condor_rm</tt>, or <tt>qdel</tt> as appropriate.
If you forget to remove them, they will exit automatically after fifteen minutes.
(This can be adjusted with the <tt>-t</tt> option to <tt>worker</tt>.)

<h2>Writing Work Queue Master Program</h2>

To write your own program using Work Queue, begin with <a
href=work_queue_example.c>C example</a> or <a
href=work_queue_example.py>Python example</a> or <a
href=work_queue_example.pl>Perl example</a> 
as a starting point.  Here is a basic outline for a Work Queue master:

<div class ="code_area"><pre class="code_snip">
q = work_queue_create(port);

    for(all tasks) {
         t = work_queue_task_create(command);
         /* add to the task description */
         work_queue_submit(q,t);
    }

    while(!work_queue_empty(q)) {
        t = work_queue_wait(q);
        work_queue_task_delete(t);
    }

work_queue_delete(q);
</pre></div>

First create a queue that is listening on a particular TCP port:
<div class="code_area">
<h4 class="code_header">C/Perl</h4>
<pre class="code_snip">
 q = work_queue_create(port);
</pre>
<h4 class="code_header">Python</h4>
<pre class="code_snip">
 q = WorkQueue(port)
</pre>
</div>

The master then creates tasks to submit to the queue. Each task consists of a
command line to run and a statement of what data is needed, and what data will
be produced by the command. Input data can be provided in the form of a file or
a local memory buffer. Output data can be provided in the form of a file or the
standard output of the program. It is also required to specify whether the
data, input or output, need to be cached at the worker site for later use. 
<p>
In the example, we specify a command that takes a single input file and produces
a single output file. We then create a task by providing the specified command
as an argument:
<div class="code_area">
<h4 class="code_header">C/Perl</h4>
<pre class="code_snip">
 t = work_queue_task_create(command);  
</pre>
<h4 class="code_header">Python</h4>
<pre class="code_snip">
 t = Task(command) 
</pre>
</div>

The input and output files associated with the execution of the task must be
explicitly specified. In the example, we also specify the executable in the
command invocation as an input file so that it is transferred and installed in
the working directory of the worker. We require this executable to be cached so
that it can be used by subsequent tasks that need it in their execution. On the
other hand, the input and output of the task are not required to be cached
since they are not used by subsequent tasks in this example.
<div class="code_area">
<h4 class="code_header">C/Perl</h4>
<pre class="code_snip">
 work_queue_task_specify_file(t,"/usr/bin/gzip","gzip",WORK_QUEUE_INPUT,WORK_QUEUE_CACHE); 
 work_queue_task_specify_file(t,infile,infile,WORK_QUEUE_INPUT,WORK_QUEUE_NOCACHE); 
 work_queue_task_specify_file(t,outfile,outfile,WORK_QUEUE_OUTPUT,WORK_QUEUE_NOCACHE);
</pre>
<h4 class="code_header">Python</h4>
<pre class="code_snip">
 t.specify_file("/usr/bin/gzip","gzip",WORK_QUEUE_INPUT,cache=True); 
 t.specify_file(infile,infile,WORK_QUEUE_INPUT,cache=False)  
 t.specify_file(outfile,outfile,WORK_QUEUE_OUTPUT,cache=False) 
</pre>
</div>

Note that the specified input directories and files for each task are
transferred and setup in the sandbox directory of the worker (unless an absolute
path is specified for their location). This sandbox serves as the initial
working directory of each task executed by the worker. The task outputs are also
stored in the sandbox directory (unless an absolute path is specified for their
storage). The path of the sandbox directory is exported to the execution
environment of each worker through the WORK_QUEUE_SANDBOX shell environment
variable. This shell variable can be used in the execution environment of
the worker to describe and access the locations of files in the sandbox
directory. An example of its usage is given below:
<div class="code_area">
<h4 class="code_header">C/Perl</h4>
<pre class="code_snip">
 t = work_queue_task_create("$WORK_QUEUE_SANDBOX/gzip < a > a.gz");  
</pre>
<h4 class="code_header">Python</h4>
<pre class="code_snip">
 t = Task("$WORK_QUEUE_SANDBOX/gzip < a > a.gz")  
</pre>
</div>

<p>
We can also run a program that is already installed at the remote site, where
the worker runs, by specifying its installed location in the command line of the
task (and removing the specification of the executable as an input file). For
example:
<div class="code_area">
<h4 class="code_header">C/Perl</h4>
<pre class="code_snip">
 t = work_queue_task_create("/usr/bin/gzip < a > a.gz");  
</pre>
<h4 class="code_header">Python</h4>
<pre class="code_snip">
 t = Task("/usr/bin/gzip < a > a.gz")  
</pre>
</div>

Once a task has been fully specified, it can be submitted to the queue where it
gets assigned a unique taskid:
<div class="code_area">
<h4 class="code_header">C/Perl</h4>
<pre class="code_snip">
 taskid = work_queue_submit(q,t);
</pre>
<h4 class="code_header">Python</h4>
<pre class="code_snip">
 taskid = q.submit(t)
</pre>
</div>

Next, wait for a task to complete, stating how long you are willing
to wait for a result, in seconds.  (If no tasks have completed by the timeout,
<tt>work_queue_wait</tt> will return null.)
<div class="code_area">
<h4 class="code_header">C/Perl</h4>
<pre class="code_snip">
 t = work_queue_wait(q,5);
</pre>
<h4 class="code_header">Python</h4>
<pre class="code_snip">
 t = q.wait(5)
</pre>
</div>

A completed task will have its output files written to disk.
You may examine the standard output of the task in <tt>t->output</tt>
and the exit code in <tt>t->exit_status</tt>. When you are done
with the task, delete it:
<div class="code_area">
<h4 class="code_header">C/Perl</h4>
<pre class="code_snip">
 work_queue_task_delete(t);
</pre>
<h4 class="code_header">Python</h4>
<pre class="code_snip">
 Deleted automatically when task object goes out of scope
</pre>
</div>

Continue submitting and waiting for tasks until all work is complete.  You may
check to make sure that the queue is empty with <tt>work_queue_empty</tt>. When
all is done, delete the queue:
<div class="code_area">
<h4 class="code_header">C/Perl</h4>
<pre class="code_snip">
 work_queue_delete(q);
</pre>
<h4 class="code_header">Python</h4>
<pre class="code_snip">
 Deleted automatically when work_queue object goes out of scope
</pre>
</div>

Full details of all of the Work Queue functions can be found in
the <a href="http://www.cse.nd.edu/~ccl/software/manuals/api/html/work__queue_8h.html">Work Queue API</a>.

<h2>Project names</h2>
Keeping track of the master's hostname and port can get cumbersome, especially
if there are multiple masters. To help with difficulty, we provide the project
name feature to identify a Work Queue master with a more recognizable project
name. Work Queue workers can then be started for their masters by providing the
project names. 

<p> The project name feature uses the <b>catalog server</b> to maintain and
track the project names of masters and their respective locations. It works as
follows: the master advertises its project name along with its hostname and port
to the catalog server. Work Queue workers that are provided with the master's
project name query the catalog server to find the hostname and port of the
master with the given project name. So, to utilize this feature, the master
must be specified to run in the <tt>WORK_QUEUE_MASTER_MODE_CATALOG</tt>. 

<p>For example, to have a Work Queue master advertise its project name as
<tt>myproject</tt>, add the following code snippet after creating the queue:
<div class="code_area">
<h4 class="code_header">C/Perl</h4>
<pre class="code_snip">
 work_queue_specify_master_mode(q, WORK_QUEUE_MASTER_MODE_CATALOG)
 work_queue_specify_name(q, "myproject");
</pre>
<h4 class="code_header">Python</h4>
<pre class="code_snip">
 wq.specify_mode(WORK_QUEUE_MASTER_MODE_CATALOG)
 wq.specify_name("myproject")
</pre>
</div>

To start a worker for this master, specify the project name (<tt>myproject</tt>)
to connect in the </tt>-N</tt> option:

<div class ="code_area"><pre class="code_snip">
work_queue_worker -N myproject 
</pre></div>

You can start ten workers for this master on Condor using
<tt>condor_submit_workers</tt> by providing the same option arguments.:
<div class ="code_area"><pre class="code_snip">
% condor_submit_workers -N myproject 10 
Submitting job(s).......... 
Logging submit event(s).......... 
10 job(s) submitted to cluster 298.
</pre></div>

Or similarly on SGE using <tt>sge_submit_workers</tt> as:
<div class ="code_area"><pre class="code_snip">
% sge_submit_workers -N myproject 10
Your job 153097 ("worker.sh") has been submitted 
Your job 153098 ("worker.sh") has been submitted 
Your job 153099 ("worker.sh") has been submitted 
...
</pre></div>

<h2>Security</h2>

By default, Work Queue does <b>not</b> perform any authentication,
so any workers will be able to connect to your master, and
vice versa.  This may be fine for a short running anonymous application,
but is not safe for a long running application with a public name.
<p>
We recommend that you enable a password for your applications.  Create
a file (e.g. <tt>mypwfile</tt>) that contains any password (or other
long phrase) that you like (e.g. <tt>This is my password</tt>).  The password
will be particular to your application and should not match any other
passwords that you own.  Note that the contents of the file are taken
verbatim as the password; this means that any new line character at
the end of the phrase will be considered as part of the password.
<p>
Then, modify your master program to use the password:
<div class="code_area">
<h4 class="code_header">C/Perl</h4>
<pre class="code_snip">
 work_queue_specify_password_file(q,mypwfile);
</pre>
<h4 class="code_header">Python</h4>
<pre class="code_snip">
 q.specify_password_file(mypwfile)
</pre>
</div>
<p>
And give the <tt>--password</tt> option to give the same password file to your
workers:
<div class ="code_area"><pre class="code_snip">
work_queue_worker --password mypwfile  MACHINENAME 9123 
</pre></div>
<p>
With this option enabled, both the master and the workers will
verify that the other has the matching password before proceeding.
The password is not sent in the clear, but is securely verified
through a SHA1-based challenge-response protocol.

<h2>Work Queue Foremen</h2>
<p>A Work Queue foreman allows Work Queue workers to be managed in an
hierarchical manner. Each foreman connects to the Work Queue master and accepts
tasks as though it were a worker. It then accepts connections from Work Queue
workers and dispatches tasks to them as if it were the master.</p> 

<p>A setup using foremen is beneficial when there are common files that need to
be transmitted to workers and cached for subsequent executions.  In this case,
the foremen transfer the common files to their workers without requiring any
intervention from the master, thereby lowering the communication and transfer
overheads at the master. </p>

<p>Foremen are also useful when harnessing resources from multiple clusters. A
foreman can be run on the head node of a cluster acting as a single
communications hub for the workers in that cluster.  This reduces the network
connections leaving the cluster and minimizes the transfer costs for sending
data into the cluster over wide area networks. </p>

<p>To start a Work Queue foreman, invoke <tt>work_queue_worker</tt> with the
<tt>--foreman</tt> argument. The foreman can advertise a project name using the
<tt>-N</tt> option to enable workers to find and connect to it without being
given its hostname and port.  On the other end, the foreman will connect to the
master with the same project name specified in <tt>-M</tt> argument
(alternatively, the hostname and port of the master can be provided instead of
its project name).

<p>For example, to run a foreman that works for a master with project name
<tt>myproject</tt> and advertises itself as <tt>foreman_myproject</tt>:
<div class ="code_area"><pre class="code_snip">
% work_queue_worker --foreman -M myproject -N foreman_myproject 
</pre></div>

<p>To run a worker that connects to a foreman, specify the foreman's project name
in the <tt>-N</tt> option. For example: 
<div class ="code_area"><pre class="code_snip">
% work_queue_worker -N foreman_myproject 
</pre></div>

<h2>Multi-slot workers</h2>

<p>The Work Queue workers, by default, advertise a single slot spanning a single
core. As a result, the workers only execute a single core task by default.

<p>The multi-slot feature enables workers to span across all available resources
(cores, memory, disk) and simultaneously execute multiple tasks that can be
accomodated within the available resource sizes.

<p>To start a multi-slot worker, you can specify the worker to automatically
report the number of cores present at its execution site as: 
<div class ="code_area"><pre class="code_snip">
% work_queue_worker --cores 0  MACHINENAME 9123
</pre></div>

<p>Note that the worker always reports the available memory and disk space
observed at its execution site.

<p>You can also manually specify the cores, memory, and disk that a worker
should report back to the master as being available using the <tt>cores</tt>,
<tt>memory</tt>, and <tt>disk</tt> command-line arguments. For example, to have
a worker report 2 cores, 1 GB of memory, and 8 GB of disk as being available for
task executions, do:
<div class ="code_area"><pre class="code_snip">
% work_queue_worker --cores 2 --memory 1000 --disk 8000  MACHINENAME 9123
</pre></div>

<p>To take advantage of the multi-slot workers, the tasks submitted to the Work
Queue need to be annotated with their resource requirements in terms of cores,
memory, and disk.

<div class="code_area">
<h4 class="code_header">C/Perl</h4>
<pre class="code_snip">
 work_queue_task_specify_cores(t, 2); //needs 2 cores 
 work_queue_task_specify_memory(t, 100); //needs 100 MB memory
 work_queue_task_specify_disk(t, 1000); //needs 1 GB disk

</pre>
<h4 class="code_header">Python</h4>
<pre class="code_snip">
 t.specify_cores(2) #needs 2 cores
 t.specify_memory(100) #needs 100 MB memory
 t.specify_disk(1000) #needs 1 GB disk
</pre>
</div>

<p> Note that if no requirements are specified, a task consumes an entire
worker. If one or more requirements are specified, a task is assumed to consume
those requirements and the unlabeled resource requirements are assumed to be
negligible.  For example, if you annotate a task as using 1 core, but don't
specify its memory or disk requirements, then Work Queue will schedule two such
tasks to a two-slot worker, regardless of their memory or disk usage.

<h2>Advanced Usage</h2>

The technique described above is suitable for distributed programs of
tens to hundreds of workers.  As you scale your program up to larger sizes,
you may find the following features helpful.  All are described in the
<a href="http://www.cse.nd.edu/~ccl/software/manuals/api/html/work__queue_8h.html">Work Queue API</a>.

<ul>
<li><b>Pipelined Submission.</b>  If you have a <b>very</b> large number of tasks to run,
it may not be possible to submit all of the tasks, and then wait for all of them.  Instead,
submit a small number of tasks, then alternate waiting and submiting to keep a constant
number in the queue.  <tt>work_queue_hungry</tt> will tell you if more submission are warranted.
<p>
<li><b>Asynchronous transfer.</b> If you have tasks with a balanced or large
computation-to-data ratio, this feature can help improve the CPU utilization and
lower the runtime overheads incurred due to data transfer. This feature
asynchronously streams the data inputs and outputs to and from the workers when
they are executing tasks. See <tt>work_queue_specify_asynchrony</tt>.
<p>
<li><b>Fast Abort.</b>  A large computation can often be slowed down by stragglers.  If you have
a large number of small tasks that take a short amount of time, then Fast Abort can help.
The Fast Abort feature keeps statistics on tasks execution times and proactively aborts tasks
that are statistical outliers.  See <tt>work_queue_activate_fast_abort</tt>.
<p>
<li><b>Immediate Data.</b>  For a large number of tasks or workers, it may be impractical
to create local input files for each one.  If the master already has the necessary input
data in memory, it can pass the data directly to the remote task with
<tt>work_queue_task_specify_buffer</tt>.
<p>
<li><b>String Interpolation.</b>  If you have workers distributed across
multiple operating systems (such as Linux, Cygwin, Solaris) and/or architectures (such
as i686, x86_64) and have files specific to each of these systems, this feature 
will help. The strings $OS and $ARCH are available for use in the specification of input
file names. Work Queue will automatically resolve these strings to the operating system
and architecture of each connected worker and transfer the input file corresponding
to the resolved file name. For example:
<div class="code_area">
<h4 class="code_header">C/Perl</h4>
<pre class="code_snip">
 work_queue_task_specify_file(t,"a.$OS.$ARCH","a",WORK_QUEUE_INPUT,WORK_QUEUE_CACHE);
</pre>
<h4 class="code_header">Python</h4>
<pre class="code_snip">
 t.specify_file("a.$OS.$ARCH","a",WORK_QUEUE_INPUT,cache=True)
</pre>
</div>
This will transfer <tt>a.Linux.x86_64</tt> to workers running on a Linux system
with an x86_64 architecture and <tt>a.Cygwin.i686</tt> to workers on Cygwin with
an i686 architecture. 
<p>
Note this feature is specifically designed for specifying and distingushing
input file names for different platforms and architectures. Also, this is
different from the $WORK_QUEUE_SANDBOX shell environment variable that exports
the location of the working directory of the worker to its execution
environment.
<p>
<li><b>Cancel Task.</b> This feature is useful in workflows where there are redundant tasks 
or tasks that become obsolete as other tasks finish. Tasks that have been submitted can be 
cancelled and immediately retrieved without waiting for Work Queue to return them in 
<tt>work_queue_wait</tt>. The tasks to cancel can be identified by either their 
<tt>taskid</tt> or <tt>tag</tt>. For example:
<div class="code_area">
<h4 class="code_header">C/Perl</h4>
<pre class="code_snip">
 t = work_queue_cancel_by_tasktag(q,"task3");
</pre>
<h4 class="code_header">Python</h4>
<pre class="code_snip">
 t = q.cancel_by_tasktag("task3")
</pre>
</div>
This cancels a task with <tt>tag</tt> named 'task3'. Note that in the presence of tasks with 
the same tag, <tt>work_queue_cancel_by_tasktag</tt> will cancel and retrieve only one of the 
matching tasks.
<p>
<li><b>Statistics.</b>  The queue tracks a fair number of statistics that count the number
of tasks, number of workers, number of failures, and so forth.  Obtain this data with <tt>work_queue_get_stats</tt>
in order to make a progress bar or other user-visible information.
</ul>

<h2>For More Information</h2>

For the latest information about Work Queue, please visit our <a
href="http://www.cse.nd.edu/~ccl/software/workqueue">web site</a> and
subscribe to our <a href="http://www.cse.nd.edu/~ccl/software/help.shtml">mailing
list</a>.

</body>
</html>
