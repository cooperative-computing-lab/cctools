<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<html>

<head>
    <meta http-equiv="Content-Type" content="text/html;charset=utf-8">
    <link rel="stylesheet" type="text/css" href="manual.css">
    <title>Confuga User's Manual</title>
</head>

<body>
    <div id="manual">
        <h1>Confuga User's Manual</h1>
        <p style="text-align: right;"><b>Last edited: May 2015</b></p>

        <p id="copyright">Confuga is Copyright (C) 2015 The University of Notre Dame.<br/>
        All rights reserved.<br/>
        This software is distributed under the GNU General Public License.<br/>
        See the file COPYING for details.</p>

        <p><b>Please use the following citation for Confuga in a scientific publication:</b></p>
        <ul>
            <li>Patrick Donnelly, Nicholas Hazekamp, Douglas Thain, <a href="http://ccl.cse.nd.edu/research/papers/confuga-ccgrid2015.pdf">Confuga: Scalable Data Intensive Computing for POSIX Workflows</a>, IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing, May, 2015.</li>
        </ul>

        <h2 id="overview">Overview<a class="sectionlink" href="#overview" title="Link to this section.">&#x21d7;</a></h2>

            <p>Confuga is an active storage cluster file system designed for
            executing DAG-structured scientific workflows. It is used as a
            collaborative distributed file system and as a platform for
            execution of scientific workflows with full data locality for all
            job dependencies.</p>

            <p>A high-level perspective of Confuga is visualized in the figure
            below.</p>

            <img src="images/confuga.png" />

            <p>Confuga is composed of a head node and multiple storage nodes.
            The head node acts as the metadata server and job scheduler for the
            cluster. Users interact with Confuga using the head node.  All file
            and job operations go through the head node.</p>

            <p>A Confuga cluster can be setup as an ordinary user or maintained
            as a dedicated service within the cluster. The head node and
            storage nodes run the <a href="chirp.html">Chirp</a> file system
            service.
            Users may interact with Confuga using Chirp's client toolset <a class="man" href="man/chirp.html">chirp(1)</a>, <a href="parrot.html">Parrot</a> <a class="man" href="man/parrot_run.html">parrot_run(1)</a>, or <a href="chirp.html#access">FUSE</a> <a class="man" href="man/chirp_fuse.html">chirp_fuse(1)</a>.</p>

            <p>Confuga manages the details of scheduling and executing jobs for
            you. However, it does not concern itself with job ordering; it
            appears as a simple batch execution platform.  We recommend using a
            high-level workflow execution system like <a
            href="makeflow.html">Makeflow</a> to manage your workflow and to
            handle the details of submitting jobs. However, you can also
            program job submmission directly using the <a
            href="chirp.html#jobs">Chirp job protocol</a>.</p>

            <p>Confuga is designed to exploit the unique parameters and
            characteristics of POSIX scientific workflows. Jobs are single task
            POSIX applications that are expressed with all input files and all
            output files. Confuga uses this restricted job specification to
            achieve performance and to control load within the cluster.</p>

            <p>To get started using Confuga, please begin by <a
            href="install.html">installing CCTools</a> on your system. When you
            are ready, proceed with the <a href="#starting">Getting Started</a>
            section below.</p>

        <h2 id="starting">Getting Started with Confuga<a class="sectionlink" href="#starting" title="Link to this section.">&#x21d7;</a></h2>
            <p>Getting a Confuga cluster up and running is extremely simple. There are three services you need to start to get an operational cluster:</p>

            <ul>

                <li><b>The Storage Nodes (1 or more).</b> You must start a number of
                storage nodes which host data and execute jobs, all managed by
                Confuga. Each storage node is a Chirp server.  Each storage
                node is added to the list of nodes passed to the Confuga head
                node.</li>

                <li><b>The Confuga Head Node.</b> This is naturally the core
                service for the cluster. It manages the storage nodes,
                distributing data and jobs.</li>

                <li><b>The Catalog Server (Optional).</b> The catalog server
                keeps track of operational storage nodes. It functions as a
                heartbeat listener for the Confuga head node. This service is
                optional because you may use the default catalog server managed
                by the Cooperative Computing Lab. Or you can start your
                own.</li>

            </ul>

            <h3 id="starting.cluster">Running a Test Cluster<a class="sectionlink" href="#starting.cluster" title="Link to this section.">&#x21d7;</a></h3>

                <p>Let's get started quickly by setting up a 2 storage node
                test cluster on your local workstation. Because we are running
                these storage nodes on <tt>localhost</tt>, we use a self-hosted
                catalog. Otherwise, the head node will not be able to match
                storage nodes (localhost is ambiguous in a global list of
                servers).</p>

                <p><b>The Catalog:</b>
                <code><span class="prompt">$ </span>catalog_server --history=catalog.history \
    --update-log=catalog.update \
    --interface=127.0.0.1 \
    &amp;</code>

                <p><b>Storage Node 1:</b>
                <code><span class="prompt">$ </span>chirp_server \
    --advertise=localhost \
    --catalog-name=localhost \
    --catalog-update=10s \
    --interface=127.0.0.1 \
    --jobs \
    --job-concurrency=10 \
    --root=./root.1 \
    --port=9001 \
    --project-name=`whoami`-test \
    --transient=./tran.1 \
    &amp;</code>
                </p>

                <p><b>Storage Node 2:</b>
                <code><span class="prompt">$ </span>chirp_server \
    --advertise=localhost \
    --catalog-name=localhost \
    --catalog-update=10s \
    --interface=127.0.0.1 \
    --jobs \
    --job-concurrency=10 \
    --root=./root.2 \
    --port=9002 \
    --project-name=`whoami`-test \
    --transient=./tran.2 \
    &amp;</code>
                </p>

                <p><b>The Head Node:</b>
                <code><span class="prompt">$ </span>chirp_server \
    --advertise=localhost \
    --catalog-name=localhost \
    --catalog-update=30s \
    --debug=confuga \
    --jobs \
    --port=9000 \
    --project-name=`whoami`-test \
    --root='confuga://./confuga.root/?auth=unix&amp;nodes=node:chirp://localhost:9001/,chirp://localhost:9002/'</code>
                </p>

                <p>Confuga will output debug information to your terminal, so
                you can see what is happening. In another terminal, use
                <tt>chirp_status</tt> to query the catalog allowing you to see
                the status of the cluster:</p>

                <code><span class="prompt">$ </span>chirp_status --catalog=localhost --server-project=`whoami`-test
TYPE     NAME                      PORT  OWNER      VERSION     TOTAL    AVAIL
chirp    localhost.localdomain     9002  batrick    4.4.0     81.6 GB  17.0 GB
chirp    localhost.localdomain     9001  batrick    4.4.0     81.6 GB  17.0 GB
chirp    localhost.localdomain     9094  batrick    4.4.0    163.1 GB  34.0 GB</code>

                <p>This example cluster also appears at the end of the Confuga manpage <a class="man" href="man/confuga.html">confuga(1)</a>.</p>

            <h3 id="starting.workflow">Running a Workflow<a class="sectionlink" href="#starting.workflow" title="Link to this section.">&#x21d7;</a></h3>

                <p>In another terminal, we can run the <a href="makeflow.html#language">standard Makeflow example</a> against the cluster to confirm everything works. This example Makeflow is distributed with CCTools in <tt>makeflow/example/example.makeflow</tt>.</p>

                <code><span class="prompt">$ </span>makeflow --batch-type=chirp --working-dir=chirp://localhost:9000/ makeflow/example/example.makeflow
parsing makeflow/example/example.makeflow...
checking makeflow/example/example.makeflow for consistency...
makeflow/example/example.makeflow has 6 rules.
recovering from log file makeflow/example/example.makeflow.makeflowlog...
starting workflow....
submitting job: /usr/bin/curl -o capitol.jpg http://ccl.cse.nd.edu/images/capitol.jpg
submitted job 14
job 14 completed
submitting job: /usr/bin/convert -swirl 360 capitol.jpg capitol.360.jpg
submitted job 15
submitting job: /usr/bin/convert -swirl 270 capitol.jpg capitol.270.jpg
submitted job 16
submitting job: /usr/bin/convert -swirl 180 capitol.jpg capitol.180.jpg
submitted job 17
submitting job: /usr/bin/convert -swirl 90 capitol.jpg capitol.90.jpg
submitted job 18
job 15 completed
job 16 completed
job 17 completed
job 18 completed
submitting job: /usr/bin/convert -delay 10 -loop 0 capitol.jpg capitol.90.jpg capitol.180.jpg capitol.270.jpg capitol.360.jpg capitol.270.jpg capitol.180.jpg capitol.90.jpg capitol.montage.gif
submitted job 19
job 19 completed
nothing left to do.</code>

                <p>You can then view the result by fetching the output and using your favorite <tt>gif</tt> viewing program:</p>
                <code><span class="prompt">$ </span>chirp localhost get /capitol.montage.gif
903.4 KB read in 0.05s (16.1 MB/s)</code>
                <code><span class="prompt">$ </span>$ display ./capitol.montage.gif</code>

                <p>You can also achieve the same thing using <a href="parrot.html">Parrot</a>:</p>
                <code><span class="prompt">$ </span>parrot_run display /chirp/localhost/capitol.montage.gif</code>

        <h2 id="confuga">Setting up Confuga<a class="sectionlink" href="#confuga" title="Link to this section.">&#x21d7;</a></h2>
            <h3 id="confuga.nodes">Running Storage Nodes<a class="sectionlink" href="#starting.nodes" title="Link to this section.">&#x21d7;</a></h3>

                <p>Confuga uses regular Chirp servers as storage nodes. Each
                storage node is specified using the <tt>nodes</tt> Confuga
                option.  All storage node Chirp servers must be run with:</p>

                <ul>
                    <li>Ticket authentication enabled (<tt>--auth=ticket</tt>). Remember by default all authentication mechanisms are enabled.)</li>
                    <li>Job execution enabled (<tt>--jobs</tt>).)</li>
                    <li>Job concurrency of at least two (<tt>--job-concurrency=2</tt>).)</li>
                </ul>

                <p>These options are also suggested but not required:</p>

                <ul>
                    <li>More frequent Catalog updates (<tt>--catalog-update=30s</tt>).)</li>
                    <li>Project name for the cluster (<tt>--project-name=foo</tt>).)</li>
                </ul>

                <p>You must also ensure that the storage nodes and the Confuga
                head node are using the same <a class="man" href="man/catalog_server.html">catalog_server(1)</a>. By
                default, this should be the case.</p>

            <h3 id="starting.options">Confuga Options<a class="sectionlink" href="#starting.options" title="Link to this section.">&#x21d7;</a></h3>

                <p>A Chirp server acting as the Confuga head node uses normal
                <a class="man" href="man/chirp_server.html">chirp_server(1)</a> options. In order to run the Chirp
                server as the Confuga head node, use the <tt>--root</tt> switch
                with the Confuga URI. You must also enable job execution with
                the <tt>--jobs</tt> switch.</p>

                <p>The format for the Confuga URI is:</p>

                <code>confuga:///path/to/workspace?option1=value&amp;option2=value</code>

                <p>The workspace path is the location Confuga maintains metadata
                and databases for the head node. Confuga specific options are
                also passed through the URI. The two primary options are
                documented below.</p>

                <ul>

                    <li><tt style="font-weight: bold;">auth=method</tt> Enable this method for Head Node to
                    Storage Node authentication. The default is to enable all
                    available authentication mechanisms.</li>

                    <li><tt style="font-weight: bold;">nodes=node-list</tt> Sets the whitespace or comma
                    delimited list of storage nodes to use for the cluster. May
                    be specified directly as a list
                    <tt>node:&lt;node1,node2,...&gt;</tt> or as a file
                    <tt>file:&lt;node file&gt;</tt>.

                </ul>

            <p>Please refer to Confuga's man page <a class="man" href="man/confuga.html">confuga(1)</a> for a
            complete and up-to-date listing of Confuga's options.</p>

        <h2 id="jobs">Executing Jobs<a class="sectionlink" href="#jobs" title="Link to this section.">&#x21d7;</a></h2>

            <p>To execute jobs on Confuga, you must first place all of the jobs
            data requirements, including the executable itself, within Confuga.
            This can be done using Chirp's client toolset <a class="man" href="man/chirp.html">chirp(1)</a>, <a href="parrot.html">Parrot</a> <a class="man" href="man/parrot_run.html">parrot_run(1)</a>, or <a href="chirp.html#access">FUSE</a> <a class="man" href="man/chirp_fuse.html">chirp_fuse(1)</a>.</p>

            <p>Once data is located on Confuga, you may begin executing jobs.
            Normally, you will construct a workflow that executes within a
            <b>workflow namespace</b> within Confuga. In simpler terms, this is
            just the root directory your workflow operates in, probably your
            home directory on Confuga. For example, if you place your files
            in Confuga like so:</p>

            <code><span class="prompt">$ </span>chirp confuga.name.org put workflow /users/me/</code>

            <p>and your workflow looks something like this:</p>

            <code>simulation.txt: bin/sim params
    bin/sim -i params</code>

            <p>The executable used by Confuga will be
            <tt>/users/me/workflow/bin/sim</tt> and the parameter file will be
            <tt>/users/me/workflow/params</tt>. Likewise, after the job
            completes, the output will be placed
            <tt>/users/me/workflow/simulation.txt</tt>. As you may tell, the
            namespace your workflow is operating in is
            <tt>/users/me/workflow</tt>. You will give this namespace to the
            workflow manager you use along with your workflow. It describes the
            mapping relationship between the namespace the <b>job</b> executes
            within and the namespace the <b>workflow</b> executes within.</p>

            <p>As an example, you might run Makeflow for the above situation like so:</p>

            <code><span class="prompt">$ </span>makeflow -T chirp --working-dir=chirp://confuga.name.org<b>/users/me/workflow</b></code>

            <h3 id="jobs.protocol">Protocol<a class="sectionlink" href="#job.protocol" title="Link to this section.">&#x21d7;</a></h3>

            <p>Jobs are executed using the <a href="chirp.html#jobs">Chirp job
            protocol</a>. No special modifications are required to submit jobs
            to Confuga. We recommend using the Makeflow workflow manager but
            you may also program your own jobs using this protocol if so
            desired.</p>

        <h2 id="security">Security<a class="sectionlink" href="#security" title="Link to this section.">&#x21d7;</a></h2>

            <h3 id="security.authentication">Authentication<a class="sectionlink" href="#security.authentication" title="Link to this section.">&#x21d7;</a></h3>

                <p>There are three authentication realms to consider for a
                Confuga cluster: user to head node, head node to storage node,
                and storage node to storage node authentication.</p>

                <p>The head node is accessed by clients just like a regular
                Chirp server. Therefore, you authenticate with Confuga in the
                <a href="chirp.html#security.authentication">same way as
                Chirp</a>. You may enable authentication mechanisms on the head
                node using the <tt>--auth</tt> switch, documented in <a
                class="man"
                href="man/chirp_server.html">chirp_server(1)</a>.</p>

                <p>Head node authentication with storage nodes is controlled
                via the <tt>auth</tt> <a href="#options">Confuga option</a>.
                Confuga will uses these authentication mechanisms to authenticate
                with its storage nodes.</p>

                <p>Lastly, Confuga handles the details of storage node to
                storage node authentication. This is done using Chirp's <a
                href="chirp.html#tickets">ticket</a> authentication metchanism.
                You as a user do not need to do anything special to get this
                working beyond enabling ticket authentication
                (<tt>--auth=ticket</tt>) on each storage node.</p>

            <h3 id="security.authorization">Authorization<a class="sectionlink" href="#security.authorization" title="Link to this section.">&#x21d7;</a></h3>

                <p>Confuga offers the same strong authorization system as
                Chirp.  This includes per-directory access control lists (ACL).
                For information on authorization controls in Chirp, please see
                the <a href="chirp.html#security.authorization">Authorization
                section</a> in the Chirp manual.</p>

        <h2 id="debugging">Debugging<a class="sectionlink" href="#debugging" title="Link to this section.">&#x21d7;</a></h2>

            <h3 id="debugging.jobs">Debugging Jobs<a class="sectionlink" href="#debugging.jobs" title="Link to this section.">&#x21d7;</a></h3>

                <p>Confuga does not save the <tt>stdout</tt> or <tt>stderr</tt>
                of jobs.  If you need to debug your jobs by examining these
                files, you must explicitly save them. If you are using Makeflow
                to submit jobs to Confuga, you may do this simply by using
                Makeflow's <tt>--wrapper</tt> option to save these
                <tt>stdout</tt> and <tt>stderr</tt>. For example:</p>

                <code><span class="prompt">$ </span>makeflow --batch-type=chirp \\
    --working-dir=chirp://confuga.example.com/ \\
    --wrapper=$'{\\n{}\\n} &gt; stdout.%% 2&gt; stderr.%%' \\
    --wrapper-output='stdout.%%' \\
    --wrapper-output='stderr.%%'</code>

        <h2 id="notes">Notes<a class="sectionlink" href="#notes" title="Link to this section.">&#x21d7;</a></h2>

            <h3 id="notes.afs">AFS<a class="sectionlink" href="#notes.afs" title="Link to this section.">&#x21d7;</a></h3>

                <p>Storage nodes used by Confuga must <a
                href="chirp.html#jobs.afs">not use AFS as their backing
                storage</a>. Confuga requires use of the Chirp job
                <tt>LINK</tt> file binding. For this reason, it cannot use
                Chirp servers running with <tt>--root</tt> on AFS.</p>

        <h2 id="missing">Missing Features<a class="sectionlink" href="#missing" title="Link to this section.">&#x21d7;</a></h2>

            <p>Confuga is a beta quality software and is presently missing a few features that will be addressed in future releases:</p>

            <ul>
                <li><b>Space consumed by deleted data is not reclaimed.</b> A garbage collector for old files needs to be written to cleanup stale replicas on storage nodes. Please see issue <a href="https://github.com/cooperative-computing-lab/cctools/issues/827">#827</a> for updates.</li>
                <li><b>Organize storage nodes by project name.</b> Attaching a project name to storage nodes would allow Confuga to dynamically pick up new storage nodes. It also greatly simplifies specifying storage nodes. Please see issue <a href="https://github.com/cooperative-computing-lab/cctools/issues/828">#828</a> for updates.</li>
            </ul>
    </div>
</body>

</html>
